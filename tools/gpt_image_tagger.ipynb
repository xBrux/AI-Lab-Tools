{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 : Set image folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üëá Use your own image folder path.\n",
    "image_folder_path = '../images'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 : Pre-process images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 image(s) processed.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import base64\n",
    "from collections import namedtuple\n",
    "\n",
    "ImageDate = namedtuple('ImageDate', ['filename_without_extension', 'extension', 'base64_string', 'caption'])\n",
    "\n",
    "\n",
    "def convert_image_to_base64(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        encoded_string = base64.b64encode(image_file.read()).decode('utf-8')\n",
    "    return encoded_string\n",
    "\n",
    "def get_file_type(filename):\n",
    "    return os.path.splitext(filename)[1][1:]  # get file extension without dot\n",
    "\n",
    "def get_filename_without_extension(filename):\n",
    "    return os.path.splitext(filename)[0]  # get filename without extension\n",
    "\n",
    "def convert_images_in_folder(folder_path):\n",
    "    encoded_images = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp')):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            base64_string = convert_image_to_base64(file_path)\n",
    "            file_type = get_file_type(filename)\n",
    "            filename_without_extension = get_filename_without_extension(filename)\n",
    "            encoded_images.append(ImageDate(filename_without_extension, file_type, base64_string, \"\"))\n",
    "    return encoded_images\n",
    "\n",
    "base64_images = convert_images_in_folder(image_folder_path)\n",
    "\n",
    "# üêû uncomment to debug\n",
    "# for item in base64_images:\n",
    "#     print(item[0], item[1], item[2], item[3])\n",
    "\n",
    "print(f'{len(base64_images)} image(s) processed.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 : Call Azure OpenAI services.\n",
    "\n",
    "‚ùóÔ∏è‚ùóÔ∏è Don't foget to config your Azure OpenAI key:\n",
    "- Add `AZURE_OPENAI_API_KEY={your_azure_openai_key_here}` to `.env` file;\n",
    "- If it doesn't exist, create one in this project root folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The image is showing the word \"GIFBOX\" with a stylized icon resembling a square or box with a blue to purple gradient outline to the left of the text. The text itself is in a bold, sans-serif typeface, with the letters \"IFBOX\" in black and the letter \"G\" in a hollow, outlined style matching the gradient of the icon.\n",
      "The image is showing a large futuristic spacecraft positioned at the forefront, with a group of three individuals facing towards it, possibly pilots or engineers. The scene appears to be set in a vast hangar or docking station with intricate structures extending into the background where the overcast sky looms above. The lighting suggests a setting sun or artificial illumination casting a warm glow on the scene, highlighting the orange and yellow tones of the spacecraft and the surrounding environment. The presence of a smaller vehicle on the right side of the image gives a sense of scale to the massive spacecraft. It is a visually striking image that conveys a sense of anticipation and adventure.\n"
     ]
    }
   ],
   "source": [
    "from openai import AzureOpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    # https://learn.microsoft.com/en-us/azure/ai-services/openai/reference#rest-api-versioning\n",
    "    api_version=\"2023-07-01-preview\",\n",
    "    # https://learn.microsoft.com/en-us/azure/cognitive-services/openai/how-to/create-resource?pivots=web-portal#create-a-resource\n",
    "    azure_endpoint=\"https://openai-ifbox-ai.openai.azure.com\",\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    ")\n",
    "\n",
    "for item in base64_images:\n",
    "  completion = client.chat.completions.create(\n",
    "      model=\"gpt-4-vision-preview\",  # Your deployment name.\n",
    "      messages=[\n",
    "      {\n",
    "        \"role\": \"system\",\n",
    "        \n",
    "        \"content\": \n",
    "        # Edit this system message if needed.\n",
    "        \"\"\"\n",
    "        You are going to help people to describe the image.\n",
    "        You should always in english start with \"the image is showing\"      \n",
    "        \"\"\"\n",
    "      },\n",
    "      {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "          # {\n",
    "          #   \"type\": \"text\", \n",
    "          #   \"text\": \"What‚Äôs in this image?\"\n",
    "          # },\n",
    "          {\n",
    "            \"type\": \"image_url\",\n",
    "\n",
    "            # Using the image url.\n",
    "            # \"image_url\": { \"url\": \"https://ifbox.ai/static/brand.e18dbb5f.png\" },\n",
    "\n",
    "            # Using the base64 encoded image from the file.\n",
    "            \"image_url\": { \"url\": f\"data:image/{(item as ImageDate)};base64,{item[3]}\" },\n",
    "          },\n",
    "        ],\n",
    "      }\n",
    "    ],\n",
    "    max_tokens=500,\n",
    "  )\n",
    "  print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4 : Post-process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5 : Humun review."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-lab-tools",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
